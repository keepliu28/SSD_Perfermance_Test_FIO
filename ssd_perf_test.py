#!/usr/bin/env python3
"""
SSDæ€§èƒ½æµ‹è¯•å·¥å…·
"""

import os
import sys
import subprocess
import json
import time
import argparse
import csv
import statistics
from datetime import datetime
from typing import Dict, List, Optional, Any


# å…¨å±€é…ç½®
DEFAULT_TEST_DURATION = 600     # 10åˆ†é’Ÿæ ‡å‡†æµ‹è¯•(åŒæ—¶ç”¨äºé¢„çƒ­å’Œæµ‹è¯•)
DEFAULT_QUEUE_DEPTH = 32
DEFAULT_THREADS = 4
SCRIPT_VERSION = "2.5.0"

# æµ‹è¯•é…ç½®
DATA_VALIDATION_SAMPLES = 3
TEST_RETRY_COUNT = 2

# å•ä½è½¬æ¢å¸¸æ•°
MIB_TO_MBS = 1.048576  # 1 MiB/s = 1.048576 MB/s


# é¢œè‰²è¾“å‡º
class Colors:
    BOLD = '\033[1m'
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    CYAN = '\033[96m'
    END = '\033[0m'


# æµ‹è¯•ç»“æœæ•°æ®ç±»
class TestResult:
    def __init__(self, test_type: str, block_size: str, rw_pattern: str, 
                 data_points: List, statistics: Dict, evaluation: Dict,
                 execution_time: float, retry_count: int):
        self.test_type = test_type
        self.block_size = block_size
        self.rw_pattern = rw_pattern
        self.data_points = data_points
        self.statistics = statistics
        self.evaluation = evaluation
        self.execution_time = execution_time
        self.retry_count = retry_count


class SSDPerformanceTester:
    """SSDæ€§èƒ½æµ‹è¯•ä¸»ç±»"""
    
    def __init__(self):
        self.device = ""
        self.test_duration = DEFAULT_TEST_DURATION
        self.queue_depth = DEFAULT_QUEUE_DEPTH
        self.threads = DEFAULT_THREADS
        self.debug_mode = False
        self.custom_test_size = ""
        self.result_dir = ""
        self.ramp_time = 0  # æ–°å¢ramp_timeå‚æ•°
        # æ—¶é—´å‚æ•°
        self.stable_data_start_time = 5
        self.stable_data_end_time = 25
        self.sampling_interval = 5
        
    def log(self, level: str, message: str):
        """ç®€å•æ—¥å¿—è¾“å‡º"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        color = Colors.CYAN if level == "INFO" else Colors.GREEN if level == "SUCCESS" else Colors.YELLOW if level == "WARNING" else Colors.RED
        
        # åœ¨å…³é”®æ­¥éª¤ä¹‹é—´æ·»åŠ ç©ºè¡Œä»¥æé«˜å¯è¯»æ€§
        if level == "INFO" and any(keyword in message for keyword in ["å¼€å§‹æ‰§è¡Œ", "é˜¶æ®µï¼š", "æ”¶é›†ç³»ç»Ÿä¿¡æ¯", "æµ‹è¯•è®¾å¤‡"]):
            print()  # å…³é”®æ­¥éª¤å‰æ·»åŠ ç©ºè¡Œ
        
        print(f"[{color}{level}{Colors.END}][MainThread] {timestamp} {message}")
        
        # åœ¨é”™è¯¯ä¿¡æ¯åæ·»åŠ ç©ºè¡Œ
        if level == "ERROR":
            print()  # ä»…ERRORçº§åˆ«åæ·»åŠ ç©ºè¡Œ

    def check_device_access(self) -> bool:
        """æ£€æŸ¥è®¾å¤‡è®¿é—®æƒé™"""
        device_path = f'/dev/{self.device}'
        
        if not os.path.exists(device_path):
            self.log("ERROR", f"è®¾å¤‡ä¸å­˜åœ¨: {device_path}")
            return False

        try:
            # ç®€å•çš„FIOæµ‹è¯•
            subprocess.run([
                'fio', f'--filename={device_path}', '--rw=read', '--bs=4k',
                '--ioengine=libaio', '--direct=1', '--size=1M', '--runtime=1',
                '--time_based', '--name=test', '--output-format=json'
            ], capture_output=True, timeout=5, check=True)
            return True
        except Exception as e:
            self.log("ERROR", f"è®¾å¤‡è®¿é—®æµ‹è¯•å¤±è´¥: {str(e)}")
            return False

    def get_device_type(self, device: str = None) -> str:
        """è·å–è®¾å¤‡ç±»å‹"""
        if device is None:
            device = self.device
            
        try:
            dev_path = f"/sys/block/{device}"
            if not os.path.exists(dev_path):
                return "unknown"
                
            rotational = 0
            try:
                with open(f"{dev_path}/queue/rotational", 'r') as f:
                    rotational = int(f.read().strip())
            except:
                pass
                
            if device.startswith("nvme"):
                return "nvme"
            elif device.startswith("sd") and rotational == 0:
                return "sata_ssd" 
            elif rotational == 1:
                return "hdd"
            else:
                return "sata_ssd"
                
        except Exception:
            return "unknown"

    def collect_system_info(self) -> Dict[str, Any]:
        """æ”¶é›†ç³»ç»Ÿä¿¡æ¯"""
        # è·å–è®¾å¤‡å‹å·å’Œå®¹é‡ä¿¡æ¯
        device_model = self._get_device_model()
        device_capacity_gb = self._get_device_capacity_gb()
        
        return {
            "timestamp": datetime.now().isoformat(),
            "device": self.device,
            "device_type": self.get_device_type(),
            "device_model": device_model,
            "device_capacity_gb": device_capacity_gb,
                "test_config": {
                "duration": self.test_duration,
                "ramp_time": self.ramp_time,
                "queue_depth": self.queue_depth,
                "threads": self.threads,
                "test_size": self.custom_test_size or "100%"
            },
            "system": {
                "python_version": sys.version,
                "platform": sys.platform
            }
        }

    def _get_device_model(self) -> str:
        """è·å–è®¾å¤‡å‹å·ä¿¡æ¯"""
        try:
            # ä¼˜å…ˆä½¿ç”¨nvmeå‘½ä»¤è·å–ä¿¡æ¯
            if self.device.startswith("nvme"):
                # æå–æ§åˆ¶å™¨åç§°(å¦‚nvme0n1 -> nvme0)
                controller = self.device.rstrip('0123456789')
                if controller == self.device:  # nvme0n1æƒ…å†µ
                    controller = ''.join([c for c in self.device if not c.isdigit()])
                    if controller.endswith('n'):
                        controller = controller[:-1]
                
                # ä½¿ç”¨nvme listå‘½ä»¤è·å–è®¾å¤‡ä¿¡æ¯
                try:
                    result = subprocess.run(['nvme', 'list'], capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        lines = result.stdout.split('\n')
                        for i, line in enumerate(lines):
                            if self.device in line and ('LONGSYS' in line or 'Samsung' in line or 'Intel' in line or 'WD' in line):
                                # æŸ¥æ‰¾åŒ…å«å‹å·ä¿¡æ¯çš„è¡Œ
                                for j in range(max(0, i-2), min(len(lines), i+3)):
                                    if any(brand in lines[j] for brand in ['LONGSYS', 'Samsung', 'Intel', 'WD', 'Kingston', 'Crucial']):
                                        # æå–å‹å·ä¿¡æ¯
                                        parts = lines[j].split()
                                        for part in parts:
                                            if len(part) > 3 and any(char.isupper() for char in part) and any(char.isdigit() for char in part):
                                                return part
                except:
                    pass
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨smartctl
                try:
                    result = subprocess.run(['smartctl', '-i', f'/dev/{self.device}'], 
                                          capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        for line in result.stdout.split('\n'):
                            if line.startswith('Model Number:'):
                                return line.split(':', 1)[1].strip()
                            elif line.startswith('Device Model:'):
                                return line.split(':', 1)[1].strip()
                except:
                    pass
            else:
                # SATAè®¾å¤‡ä½¿ç”¨hdparmæˆ–smartctl
                try:
                    result = subprocess.run(['hdparm', '-I', f'/dev/{self.device}'], 
                                          capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        for line in result.stdout.split('\n'):
                            if 'Model Number:' in line:
                                return line.split('Model Number:')[1].strip()
                except:
                    pass
                
                try:
                    result = subprocess.run(['smartctl', '-i', f'/dev/{self.device}'], 
                                          capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        for line in result.stdout.split('\n'):
                            if line.startswith('Device Model:'):
                                return line.split(':', 1)[1].strip()
                            elif line.startswith('Model Number:'):
                                return line.split(':', 1)[1].strip()
                except:
                    pass
                    
        except Exception:
            pass
            
        return "Unknown"
    
    def _get_device_capacity_gb(self) -> float:
        """è·å–è®¾å¤‡å®¹é‡(GB)"""
        try:
            # ä¼˜å…ˆä½¿ç”¨nvmeå‘½ä»¤è·å–ç²¾ç¡®å®¹é‡
            if self.device.startswith("nvme"):
                try:
                    result = subprocess.run(['nvme', 'list'], capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        lines = result.stdout.split('\n')
                        for line in lines:
                            if self.device in line and 'TB' in line:
                                # è§£æå®¹é‡ä¿¡æ¯,å¦‚ "3.20 TB"
                                import re
                                match = re.search(r'(\d+\.?\d*)\s*(TB|GB)', line)
                                if match:
                                    size = float(match.group(1))
                                    unit = match.group(2)
                                    if unit == 'TB':
                                        return size * 1024
                                    else:
                                        return size
                except:
                    pass
                
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨smartctlè·å–å®¹é‡
                try:
                    result = subprocess.run(['smartctl', '-i', f'/dev/{self.device}'], 
                                          capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        for line in result.stdout.split('\n'):
                            if 'Total NVM Capacity:' in line or 'user capacity:' in line.lower():
                                # è§£æå®¹é‡ä¿¡æ¯,å¦‚ "3,200,631,791,616 [3.20 TB]"
                                import re
                                # æŸ¥æ‰¾TBæˆ–GBæ•°å€¼
                                tb_match = re.search(r'\[(\d+\.?\d*)\s*TB\]', line)
                                gb_match = re.search(r'\[(\d+\.?\d*)\s*GB\]', line)
                                
                                if tb_match:
                                    return float(tb_match.group(1)) * 1024
                                elif gb_match:
                                    return float(gb_match.group(1))
                except:
                    pass
            else:
                # SATAè®¾å¤‡å®¹é‡è·å–
                try:
                    result = subprocess.run(['blockdev', '--getsize64', f'/dev/{self.device}'], 
                                          capture_output=True, text=True, timeout=10)
                    if result.returncode == 0:
                        size_bytes = int(result.stdout.strip())
                        return size_bytes / (1024**3)  # è½¬æ¢ä¸ºGB
                except:
                    pass
                    
        except Exception:
            pass
            
        return 0.0
    
    def _execute_single_test(self, test_type: str, block_size: str, rw_pattern: str, 
                           queue_depth: int = None, numjobs: int = None, sample_id: int = 0) -> TestResult:
        """æ‰§è¡Œå•æ¬¡æµ‹è¯•"""
        output_prefix = f"{test_type}_{block_size}_{rw_pattern}"
        if sample_id > 0:
            output_prefix += f"_sample{sample_id}"
            
        output_json = os.path.join(self.result_dir, f"{output_prefix}.json")
        
        # ä½¿ç”¨æŒ‡å®šçš„é˜Ÿåˆ—æ·±åº¦å’Œä»»åŠ¡æ•°,å¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼
        test_queue_depth = queue_depth if queue_depth is not None else self.queue_depth
        test_numjobs = numjobs if numjobs is not None else self.threads
        
        # æ„å»ºFIOå‘½ä»¤
        # å¦‚æœç”¨æˆ·é€šè¿‡ --size æŒ‡å®šäº†æµ‹è¯•å¤§å°ï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨ï¼›å¦åˆ™é»˜è®¤ 100%
        fio_size = self.custom_test_size or "100%"
        fio_cmd = [
            "fio",
            f"--name={output_prefix}",
            f"--filename=/dev/{self.device}",
            "--ioengine=libaio",
            "--direct=1",
            f"--numjobs={test_numjobs}",
            f"--iodepth={test_queue_depth}",
            f"--rw={rw_pattern}",
            f"--bs={block_size}",
            f"--runtime={self.test_duration}",
            f"--ramp_time={self.ramp_time}",
            "--time_based=1",
            f"--size={fio_size}",
            "--refill_buffers",
            "--end_fsync=1",
            "--norandommap=1",
            "--randrepeat=0",
            "--group_reporting",
            "--output-format=json",
            f"--output={output_json}"
        ]
        
        # åªåœ¨ç¬¬ä¸€æ¬¡é‡‡æ ·æ—¶æ‰“å°å®Œæ•´å‘½ä»¤
        if sample_id == 0:
            cmd_str = ' '.join(fio_cmd)
            self.log("INFO", f"FIOå‘½ä»¤: {cmd_str}")
        
        # æ‰§è¡Œå‘½ä»¤
        start_time = time.time()
        result = subprocess.run(fio_cmd, capture_output=True, text=True)
        execution_time = time.time() - start_time
        
        if result.returncode != 0:
            error_msg = f"å‘½ä»¤æ‰§è¡Œå¤±è´¥ (è¿”å›ç : {result.returncode})"
            # å°½å¯èƒ½æŠŠ FIO çš„ stderr/stdout å…³é”®ä¿¡æ¯æ‰“åˆ°æ—¥å¿—é‡Œï¼Œæ–¹ä¾¿æ’æŸ¥é—®é¢˜
            stderr_preview = (result.stderr or "").strip()
            stdout_preview = (result.stdout or "").strip()
            if stderr_preview:
                self.log("ERROR", f"FIO stderr: {stderr_preview[:800]}")
            if stdout_preview:
                self.log("ERROR", f"FIO stdout: {stdout_preview[:400]}")
            self.log("ERROR", f"=== å‘½ä»¤æ‰§è¡Œå¤±è´¥è¯¦æƒ… ===")
            raise Exception(error_msg)
        
        # åŠ è½½å’ŒéªŒè¯ç»“æœ
        json_data = self._load_and_validate_json(output_json)
        if not json_data:
            raise Exception("ç»“æœæ–‡ä»¶æ— æ•ˆæˆ–ä¸ºç©º")
            
        # è°ƒè¯•ï¼šæ‰“å°JSONç»“æ„
        if self.debug_mode and sample_id == 0:
            print(f"è°ƒè¯•: JSONæ•°æ®ç»“æ„={json.dumps(json_data, indent=2)[:1000]}...")
            print(f"è°ƒè¯•: job options={json_data.get('jobs', [{}])[0].get('job options', {})}")
        
        # æå–æ€§èƒ½æŒ‡æ ‡
        metrics = self._extract_performance_metrics({
            "json_data": json_data,
            "job_name": output_prefix,
            "execution_time": execution_time
        })
        
        # åˆ›å»ºæµ‹è¯•ç»“æœ
        test_result = TestResult(
            test_type=test_type,
            block_size=block_size,
            rw_pattern=rw_pattern,
            data_points=[],
            statistics={},
            evaluation={},
            execution_time=execution_time,
            retry_count=0
        )
        
        # å¡«å……ç»Ÿè®¡æ•°æ®
        test_result.statistics = {
            "mean": metrics.get("primary_metric", 0),
            "execution_time": execution_time
        }
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        test_result.evaluation = self._evaluate_test_result(test_result)
        
        return test_result
    
    def _load_and_validate_json(self, json_file: str) -> Optional[Dict]:
        """åŠ è½½å¹¶éªŒè¯JSONæ–‡ä»¶"""
        if not os.path.exists(json_file) or os.path.getsize(json_file) < 100:
            return None
            
        try:
            with open(json_file, "r") as f:
                data = json.load(f)
            
            if "jobs" not in data or not data["jobs"]:
                return None
                
            return data
        except json.JSONDecodeError:
            return None
    
    def _extract_performance_metrics(self, test_result: Dict) -> Dict[str, float]:
        """æå–æ€§èƒ½æŒ‡æ ‡"""
        json_data = test_result["json_data"]
        
        if not json_data or "jobs" not in json_data or not json_data["jobs"]:
            return {}
            
        job = json_data["jobs"][0]
        
        # å°è¯•ä»å¤šä¸ªåœ°æ–¹è·å–è¯»å†™æ¨¡å¼
        rw_mode = job.get("rw", "")
        if not rw_mode:
            # ä»job optionsä¸­è·å–
            job_options = job.get("job options", {})
            rw_mode = job_options.get("rw", "")
        
        # å¦‚æœè¿˜æ˜¯æ²¡æœ‰,ä»job_nameæ¨æ–­
        if not rw_mode:
            job_name = job.get("jobname", "")
            if "write" in job_name:
                rw_mode = "write"
            elif "read" in job_name:
                rw_mode = "read"
            else:
                # é»˜è®¤å‡è®¾ä¸ºå†™å…¥
                rw_mode = "write"
        
        # è·å–è¯»/å†™æ•°æ®
        read_data = job.get("read", {})
        write_data = job.get("write", {})
        
        # è°ƒè¯•ä¿¡æ¯
        if self.debug_mode:
            print(f"è°ƒè¯•: rwæ¨¡å¼={rw_mode}")
            print(f"è°ƒè¯•: job name={job.get('jobname', '')}")
            print(f"è°ƒè¯•: read io_bytes={read_data.get('io_bytes', 0)}, write io_bytes={write_data.get('io_bytes', 0)}")
        
        # ä»bw_bytesæå–å¹¶è½¬æ¢ä¸ºMB/s (1 MiB/s = 1.048576 MB/s)
        # bw_byteså•ä½æ˜¯bytes/secï¼Œéœ€è¦è½¬æ¢ä¸ºMB/s: bytes/sec / 1024^2 = MiB/sï¼Œå†è½¬æ¢ä¸ºMB/s
        read_bw_mib = read_data.get("bw_bytes", 0) / (1024 * 1024)  # è½¬æ¢ä¸ºMiB/s
        write_bw_mib = write_data.get("bw_bytes", 0) / (1024 * 1024)  # è½¬æ¢ä¸ºMiB/s
        read_bw_mbs = read_bw_mib * MIB_TO_MBS  # è½¬æ¢ä¸ºMB/s
        write_bw_mbs = write_bw_mib * MIB_TO_MBS  # è½¬æ¢ä¸ºMB/s
        
        # æ ¹æ®å®é™…çš„æ•°æ®æ¥åˆ¤æ–­è¯»å†™æ¨¡å¼,è€Œä¸æ˜¯ä¾èµ–rwå­—æ®µ
        read_io_bytes = read_data.get("io_bytes", 0)
        write_io_bytes = write_data.get("io_bytes", 0)
        
        # å¦‚æœæœ‰è¯»æ•°æ®,åˆ™ä½¿ç”¨è¯»æ€§èƒ½ï¼›å¦åˆ™ä½¿ç”¨å†™æ€§èƒ½
        if read_io_bytes > 0:
            if "rand" in rw_mode or job.get("jobname", "").startswith("random"):
                primary_metric = read_data.get("iops", 0)  # éšæœºè¯»ç”¨IOPS
            else:
                primary_metric = read_bw_mbs  # é¡ºåºè¯»ç”¨å¸¦å®½(MB/s)
        else:
            if "rand" in rw_mode or job.get("jobname", "").startswith("random"):
                primary_metric = write_data.get("iops", 0)  # éšæœºå†™ç”¨IOPS
            else:
                primary_metric = write_bw_mbs  # é¡ºåºå†™ç”¨å¸¦å®½(MB/s)
        
        # è°ƒè¯•ä¿¡æ¯
        if self.debug_mode:
            print(f"è°ƒè¯•: ä¸»è¦æŒ‡æ ‡={primary_metric}")
            print(f"è°ƒè¯•: read_bw={read_bw_mbs:.2f} MB/s, read_iops={read_data.get('iops', 0)}")
            print(f"è°ƒè¯•: write_bw={write_bw_mbs:.2f} MB/s, write_iops={write_data.get('iops', 0)}")
            
        return {
            "read_bw": read_bw_mbs,
            "read_iops": read_data.get("iops", 0),
            "read_lat": read_data.get("lat_ns", {}).get("mean", 0) / 1000,
            "write_bw": write_bw_mbs,
            "write_iops": write_data.get("iops", 0),
            "write_lat": write_data.get("lat_ns", {}).get("mean", 0) / 1000,
            "primary_metric": primary_metric,
            "execution_time": test_result.get("execution_time", 0)
        }
    
    def _evaluate_test_result(self, result: TestResult) -> Dict[str, Any]:
        """è¯„ä¼°æµ‹è¯•ç»“æœè´¨é‡"""
        evaluation = {
            "status": "SUCCESS",
            "data_quality": "GOOD",
            "notes": []
        }
        
        # åªè¯„ä¼°æ•°æ®è´¨é‡,ä¸è¿›è¡Œæ€§èƒ½ç­‰çº§è¯„ä»·
        return evaluation
    
    def retry_operation(self, operation, operation_name: str):
        """é‡è¯•æœºåˆ¶"""
        last_error = None
        for attempt in range(TEST_RETRY_COUNT + 1):
            try:
                return operation()
            except Exception as e:
                last_error = e
                if attempt < TEST_RETRY_COUNT:
                    self.log("WARNING", f"{operation_name} é‡è¯• {attempt + 1}/{TEST_RETRY_COUNT}: {str(e)}")
                    time.sleep(1)
        
        raise last_error
    
    def run_enhanced_test(self, test_type: str, block_size: str, rw_pattern: str, 
                         queue_depth: int = None, numjobs: int = None) -> TestResult:
        """è¿è¡Œå¢å¼ºæµ‹è¯•(å¤šæ¬¡é‡‡æ ·)"""
        self.log("INFO", f"å¼€å§‹å¢å¼ºæµ‹è¯•: {test_type}_{block_size}_{rw_pattern} (QD:{queue_depth or self.queue_depth}, Jobs:{numjobs or self.threads})")
        
        # æ‰§è¡Œå¤šæ¬¡é‡‡æ ·
        results = []
        for sample_id in range(DATA_VALIDATION_SAMPLES):
            try:
                result = self.retry_operation(
                    lambda: self._execute_single_test(test_type, block_size, rw_pattern, queue_depth, numjobs, sample_id),
                    f"FIOæµ‹è¯•-{test_type}_{block_size}_{rw_pattern}"
                )
                results.append(result)

            except Exception as e:
                self.log("ERROR", f"æµ‹è¯•å¤±è´¥: {str(e)}")
                # åˆ›å»ºå¤±è´¥ç»“æœ
                failed_result = TestResult(
                    test_type=test_type,
                    block_size=block_size,
                    rw_pattern=rw_pattern,
                    data_points=[],
                    statistics={},
                    evaluation={"status": "FAILED", "error": str(e)},
                    execution_time=0,
                    retry_count=TEST_RETRY_COUNT
                )
                results.append(failed_result)
        
        # åˆå¹¶ç»“æœ
        if results:
            return self._merge_test_results(results, test_type, block_size, rw_pattern)
        else:
            raise Exception("æ‰€æœ‰é‡‡æ ·å‡å¤±è´¥")
    
    def _merge_test_results(self, results: List[TestResult], test_type: str, block_size: str, rw_pattern: str) -> TestResult:
        """åˆå¹¶å¤šæ¬¡æµ‹è¯•ç»“æœ"""
        valid_results = [r for r in results if r.evaluation.get("status") != "FAILED"]
        
        if not valid_results:
            return results[0]  # è¿”å›ç¬¬ä¸€ä¸ªå¤±è´¥ç»“æœ
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        primary_metrics = [r.statistics.get("mean", 0) for r in valid_results]
        execution_times = [r.execution_time for r in valid_results]
        
        mean_value = statistics.mean(primary_metrics) if primary_metrics else 0
        stdev_value = statistics.stdev(primary_metrics) if len(primary_metrics) > 1 else 0
        cv = stdev_value / mean_value if mean_value > 0 else float('inf')  # å˜å¼‚ç³»æ•°ï¼šæ ‡å‡†å·®/å‡å€¼
        
        # åˆ›å»ºåˆå¹¶ç»“æœ
        merged_result = TestResult(
            test_type=test_type,
            block_size=block_size,
            rw_pattern=rw_pattern,
            data_points=[],
            statistics={
                "mean": mean_value,
                "stdev": stdev_value,
                "cv": cv,
                "min": min(primary_metrics) if primary_metrics else 0,
                "max": max(primary_metrics) if primary_metrics else 0,
                "sample_count": len(valid_results),
                "execution_time_mean": statistics.mean(execution_times) if execution_times else 0
            },
            evaluation={},
            execution_time=statistics.mean(execution_times) if execution_times else 0,
            retry_count=sum(r.retry_count for r in results)
        )
        
        # è¯„ä¼°åˆå¹¶ç»“æœ
        merged_result.evaluation = self._evaluate_test_result(merged_result)
        
        # æ•°æ®è´¨é‡è¯„ä¼°(åŸºäºå˜å¼‚ç³»æ•°CV)
        if cv < 0.1:  # CV<0.1: æ•°æ®ç¨³å®šæ€§æå¥½
            merged_result.evaluation["data_quality"] = "EXCELLENT"
        elif cv < 0.2:  # CV<0.2: æ•°æ®ç¨³å®šæ€§è‰¯å¥½
            merged_result.evaluation["data_quality"] = "GOOD"
        else:  # CV>0.2: æ•°æ®æ³¢åŠ¨è¾ƒå¤§
            merged_result.evaluation["data_quality"] = "POOR"
            merged_result.evaluation["notes"].append(f"æ•°æ®æ³¢åŠ¨è¾ƒå¤§,å˜å¼‚ç³»æ•°{cv:.3f}")
        
        return merged_result
    
    def run_comprehensive_test(self) -> List[TestResult]:
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯• - ä¼˜åŒ–æ•°æ®å†™å…¥ç­–ç•¥"""
        results = []
        
        # å®šä¹‰æµ‹è¯•é…ç½® - æŒ‰ç…§1)é¡ºåºå†™ 2)é¡ºåºè¯» 3)éšæœºå†™ 4)éšæœºè¯»çš„é¡ºåº
        test_configs = [
            {"test_type": "sequential", "block_size": "128k", "rw_pattern": "write", "queue_depth": 128, "numjobs": 1, "stage": "ç¬¬äºŒé˜¶æ®µï¼š128Ké¡ºåºå†™å…¥/QD128/Job1"},
            {"test_type": "sequential", "block_size": "128k", "rw_pattern": "read", "queue_depth": 128, "numjobs": 1, "stage": "ç¬¬ä¸‰é˜¶æ®µï¼š128Ké¡ºåºè¯»å–/QD128/Job1"},
            {"test_type": "random", "block_size": "4k", "rw_pattern": "write", "queue_depth": 32, "numjobs": 8, "stage": "ç¬¬äº”é˜¶æ®µï¼š4Kéšæœºå†™å…¥/QD32/Job8"},
            {"test_type": "random", "block_size": "4k", "rw_pattern": "read", "queue_depth": 32, "numjobs": 8, "stage": "ç¬¬å…­é˜¶æ®µï¼š4Kéšæœºè¯»å–/QD32/Job8"}
        ]
        
        total_tests = len(test_configs)
        self.log("INFO", f"å¼€å§‹æ‰§è¡Œä¼˜åŒ–ç‰ˆSSDæ€§èƒ½æµ‹è¯•æµç¨‹ {total_tests} ä¸ªæµ‹è¯•ç”¨ä¾‹...")

        # ç¬¬ä¸€æ­¥ï¼šé¡ºåºå†™é¢„çƒ­(ä½¿ç”¨ramp_timeå‚æ•°)
        warmup_time = self.ramp_time  # ä½¿ç”¨ramp_timeå‚æ•°
        self.log("INFO", f"ç¬¬ä¸€é˜¶æ®µï¼šé¡ºåºå†™é¢„çƒ­{warmup_time}ç§’ [QD128/Job1]")
        warmup_size = self.custom_test_size or "100%"
        try:
            seq_warmup_cmd = ["fio", "--name=seq_warmup", f"--filename=/dev/{self.device}",
                              "--rw=write", "--bs=128k", "--ioengine=libaio", "--direct=1",
                              "--numjobs=1", "--iodepth=128", f"--runtime={warmup_time}", "--time_based=1",
                              f"--size={warmup_size}", "--refill_buffers", "--end_fsync=1", 
                              "--norandommap=1", "--randrepeat=0", "--group_reporting",
                              "--output-format=json", "--output=/tmp/seq_warmup.json"]
            
            subprocess.run(seq_warmup_cmd, capture_output=True, check=False)
            self.log("SUCCESS", "é¡ºåºå†™é¢„çƒ­å®Œæˆ")
        except Exception as e:
            self.log("WARNING", f"é¡ºåºå†™é¢„çƒ­å¤±è´¥,ç»§ç»­æµ‹è¯•: {str(e)}")

        # æ‰§è¡Œæµ‹è¯•å¾ªç¯
        for i, config in enumerate(test_configs, 1):
            test_type = config["test_type"]
            block_size = config["block_size"] 
            rw_pattern = config["rw_pattern"]
            queue_depth = config["queue_depth"]
            numjobs = config["numjobs"]
            stage = config["stage"]
            
            # ç‰¹æ®Šå¤„ç†ï¼šç¬¬å››æ­¥éšæœºå†™é¢„çƒ­(ä½¿ç”¨ramp_timeå‚æ•°)
            if i == 3:  # åœ¨éšæœºå†™æµ‹è¯•å‰è¿›è¡Œé¢„çƒ­
                warmup_time = self.ramp_time  # ä½¿ç”¨ramp_timeå‚æ•°
                self.log("INFO", f"ç¬¬å››é˜¶æ®µï¼šéšæœºå†™é¢„çƒ­{warmup_time}ç§’ [QD32/Job8]")
                warmup_size = self.custom_test_size or "100%"
                try:
                    rand_warmup_cmd = ["fio", "--name=rand_warmup", f"--filename=/dev/{self.device}",
                                      "--rw=randwrite", "--bs=4k", "--ioengine=libaio", "--direct=1",
                                      "--numjobs=8", "--iodepth=32", f"--runtime={warmup_time}", "--time_based=1",
                                      f"--size={warmup_size}", "--refill_buffers", "--end_fsync=1",
                                      "--norandommap=1", "--randrepeat=0", "--group_reporting",
                                      "--output-format=json", "--output=/tmp/rand_warmup.json"]
                    
                    subprocess.run(rand_warmup_cmd, capture_output=True, check=False)
                    self.log("SUCCESS", "éšæœºå†™é¢„çƒ­å®Œæˆ")
                except Exception as e:
                    self.log("WARNING", f"éšæœºå†™é¢„çƒ­å¤±è´¥,ç»§ç»­æµ‹è¯•: {str(e)}")

            self.log("INFO", f"æ‰§è¡Œæµ‹è¯• {i+1}/{total_tests+1}: {test_type} {block_size} {rw_pattern} [{stage}]")
            self.log("INFO", f"å‚æ•°é…ç½®: é˜Ÿåˆ—æ·±åº¦={queue_depth}, ä»»åŠ¡æ•°={numjobs}")

            try:
                result = self.run_enhanced_test(test_type, block_size, rw_pattern, queue_depth, numjobs)
                results.append(result)

                # æ˜¾ç¤ºæ€§èƒ½ç»“æœ
                mean_value = result.statistics.get("mean", 0)
                # ä½¿ç”¨æ˜ç¡®çš„ç±»å‹åˆ¤æ–­ï¼Œé¿å…å­—ç¬¦ä¸²åŒ…å«å…³ç³»äº§ç”Ÿæ­§ä¹‰
                if result.test_type == "sequential":
                    performance_str = f"{mean_value:.2f} MB/s"
                else:
                    performance_str = f"{mean_value:.0f} IOPS"

                cv = result.statistics.get("cv", 0)  # å˜å¼‚ç³»æ•°ï¼šè¡¡é‡æ•°æ®ç¨³å®šæ€§
                self.log("SUCCESS", f"æµ‹è¯•å®Œæˆ - æ€§èƒ½: {performance_str}, CV: {cv:.3f}")

            except Exception as e:
                self.log("ERROR", f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
                # åˆ›å»ºå¤±è´¥ç»“æœ
                failed_result = TestResult(
                    test_type=test_type,
                    block_size=block_size,
                    rw_pattern=rw_pattern,
                    data_points=[],
                    statistics={},
                    evaluation={"status": "FAILED", "error": str(e)},
                    execution_time=0,
                    retry_count=TEST_RETRY_COUNT
                )
                results.append(failed_result)
        
        return results
    
    def save_results(self, results: List[TestResult], system_info: Dict):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        # CSVæŠ¥å‘Š
        csv_file = os.path.join(self.result_dir, "performance_report.csv")
        with open(csv_file, "w", newline="") as f:
            writer = csv.writer(f)
            writer.writerow([
            "æµ‹è¯•ç±»å‹", "å—å¤§å°", "è¯»å†™æ¨¡å¼", "ä¸»è¦æŒ‡æ ‡", "å‡å€¼", "æ ‡å‡†å·®", "å˜å¼‚ç³»æ•°",
            "æ‰§è¡Œæ—¶é—´", "é‡è¯•æ¬¡æ•°"
            ])
            
            for result in results:
                # ç¡®å®šæ­£ç¡®çš„å•ä½
                if result.test_type == "sequential":
                    unit = "MB/s"
                    format_str = f"{result.statistics.get('mean', 0):.2f}"
                else:
                    unit = "IOPS"
                    format_str = f"{result.statistics.get('mean', 0):.0f}"
                
                writer.writerow([
                    result.test_type,
                    result.block_size,
                    result.rw_pattern,
                    unit,
                    format_str,
                    f"{result.statistics.get('stdev', 0):.2f}",
                    f"{result.statistics.get('cv', 0):.3f}",
                    f"{result.execution_time:.2f}",
                    result.retry_count
                ])

        # JSONæŠ¥å‘Š
        json_file = os.path.join(self.result_dir, "performance_report.json")
        report_data = {
            "version": SCRIPT_VERSION,
            "timestamp": datetime.now().isoformat(),
            "system_info": system_info,
            "test_results": []
        }
        
        for result in results:
            result_dict = {
                "test_type": result.test_type,
                "block_size": result.block_size,
                "rw_pattern": result.rw_pattern,
                "statistics": result.statistics,
                "evaluation": result.evaluation,
                "execution_time": result.execution_time,
                "retry_count": result.retry_count
            }
            report_data["test_results"].append(result_dict)

        with open(json_file, "w") as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        # ç³»ç»Ÿä¿¡æ¯
        sysinfo_file = os.path.join(self.result_dir, "system_info.txt")
        with open(sysinfo_file, "w") as f:
            f.write(f"æµ‹è¯•æ—¶é—´: {system_info.get('timestamp', 'Unknown')}\n")
            f.write(f"è®¾å¤‡: {system_info.get('device', 'Unknown')}\n")
            f.write(f"è®¾å¤‡ç±»å‹: {system_info.get('device_type', 'Unknown')}\n")
            f.write(f"è®¾å¤‡å‹å·: {system_info.get('device_model', 'Unknown')}\n")
            f.write(f"è®¾å¤‡å®¹é‡: {system_info.get('device_capacity_gb', 0):.1f} GB\n")
            f.write(f"æµ‹è¯•é…ç½®:\n")
            for key, value in system_info.get('test_config', {}).items():
                f.write(f"  {key}: {value}\n")
            
            f.write(f"\nç³»ç»Ÿä¿¡æ¯:\n")
            for key, value in system_info.get('system', {}).items():
                f.write(f"  {key}: {value}\n")
        
        self.log("INFO", f"ç»“æœå·²ä¿å­˜åˆ°ç›®å½•: {self.result_dir}")
    
    def parse_arguments(self) -> bool:
        """è§£æå‘½ä»¤è¡Œå‚æ•°"""
        parser = argparse.ArgumentParser(description="SSDæ€§èƒ½æµ‹è¯•è„šæœ¬ (ä¿®å¤ç‰ˆæœ¬)", add_help=False)
        parser.add_argument("device", nargs="?", help="è¦æµ‹è¯•çš„è®¾å¤‡å (å¦‚: sda, nvme0n1)")
        parser.add_argument("-t", "--time", type=int, default=DEFAULT_TEST_DURATION, help=f"é¢„çƒ­å’Œæµ‹è¯•æŒç»­æ—¶é—´ (é»˜è®¤: {DEFAULT_TEST_DURATION}ç§’)")
        parser.add_argument("-q", "--queue", type=int, default=DEFAULT_QUEUE_DEPTH, help=f"é˜Ÿåˆ—æ·±åº¦ (é»˜è®¤: {DEFAULT_QUEUE_DEPTH})")
        parser.add_argument("-j", "--jobs", type=int, default=DEFAULT_THREADS, help=f"å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: {DEFAULT_THREADS})")
        parser.add_argument("-d", "--debug", action="store_true", help="å¯ç”¨è°ƒè¯•æ¨¡å¼")
        parser.add_argument("--size", type=str, metavar="SIZE", help="è‡ªå®šä¹‰æµ‹è¯•å¤§å° (ä¾‹å¦‚: 10G, 500M, 20%, 100%)")
        parser.add_argument("--ramp_time", type=int, help=f"é¢„çƒ­æ—¶é—´ (é»˜è®¤: è‡ªåŠ¨è®¾ç½®ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ)")
        parser.add_argument("-h", "--help", action="store_true", help="æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        
        try:
            # argparse åœ¨è§£æé”™è¯¯æ—¶ä¼šè°ƒç”¨ sys.exitï¼Œè¿™é‡Œæ•è· SystemExitï¼Œ
            # ç»Ÿä¸€æ‰“å°å¸®åŠ©ä¿¡æ¯å¹¶è¿”å› Falseï¼Œé¿å…è„šæœ¬ç›´æ¥é€€å‡º
            args = parser.parse_args()
        except SystemExit:
            self.show_help()
            return False
        
        if args.help or not args.device:
            self.show_help()
            return False
        
        self.device = args.device
        self.test_duration = args.time
        
        # éªŒè¯æµ‹è¯•æ—¶é—´å‚æ•°
        if self.test_duration <= 0:
            self.log("ERROR", "æµ‹è¯•æ—¶é—´å¿…é¡»å¤§äº0ç§’")
            return False
        
        # è®¾ç½®ramp_timeå‚æ•°
        if args.ramp_time is not None:
            if args.ramp_time < 0:
                self.log("ERROR", "ramp_timeä¸èƒ½ä¸ºè´Ÿæ•°")
                return False
            elif args.ramp_time >= self.test_duration:
                self.log("ERROR", "ramp_timeä¸èƒ½å¤§äºæˆ–ç­‰äºæµ‹è¯•æ—¶é—´")
                return False
            self.ramp_time = args.ramp_time
        else:
            # è‡ªåŠ¨è®¾ç½®ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ
            self.ramp_time = self.test_duration // 2
        
        self.queue_depth = args.queue
        self.threads = args.jobs
        self.debug_mode = args.debug
        self.custom_test_size = getattr(args, 'size', "")
        
        return True
    
    def show_help(self) -> None:
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        help_text = f"""
SSDæ€§èƒ½æµ‹è¯•è„šæœ¬ v{SCRIPT_VERSION} (ä¿®å¤ç‰ˆæœ¬)

ç”¨æ³•:
    python ssd_perf_test.py [é€‰é¡¹] <è®¾å¤‡å>

å»ºè®®çš„æµ‹è¯•å‘½ä»¤:
    python3 ssd_perf_test.py nvme0n1 --debug

å¿…éœ€å‚æ•°:
    <è®¾å¤‡å>         è¦æµ‹è¯•çš„SSDè®¾å¤‡å (å¦‚: sda, nvme0n1)

å¯é€‰å‚æ•°:
    -t, --time      é¢„çƒ­å’Œæµ‹è¯•æŒç»­æ—¶é—´ (é»˜è®¤: {DEFAULT_TEST_DURATION}ç§’)
    -q, --queue     é˜Ÿåˆ—æ·±åº¦ (é»˜è®¤: {DEFAULT_QUEUE_DEPTH})
    -j, --jobs      å¹¶å‘çº¿ç¨‹æ•° (é»˜è®¤: {DEFAULT_THREADS})
    -d, --debug     å¯ç”¨è°ƒè¯•æ¨¡å¼
    --size          è‡ªå®šä¹‰æµ‹è¯•å¤§å° (é»˜è®¤: 100%,ä¾‹å¦‚: 10G, 500M, 20%, 100%)
    --ramp_time     é¢„çƒ­æ—¶é—´ (é»˜è®¤: è‡ªåŠ¨è®¾ç½®ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ)
    -h, --help      æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

=== ä¼˜åŒ–ç‰ˆæµ‹è¯•æµç¨‹ ===

1. é¡ºåºå†™é¢„çƒ­ (ä½¿ç”¨--ramp_timeå‚æ•°æŒ‡å®šæ—¶é—´, é»˜è®¤ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ, QD128/Job1)
2. 128Ké¡ºåºå†™å…¥æµ‹è¯• (ä½¿ç”¨-tå‚æ•°æŒ‡å®šæ—¶é—´, é»˜è®¤10åˆ†é’Ÿ, é˜Ÿåˆ—æ·±åº¦:128, ä»»åŠ¡æ•°:1)
3. 128Ké¡ºåºè¯»å–æµ‹è¯• (ä½¿ç”¨-tå‚æ•°æŒ‡å®šæ—¶é—´, é»˜è®¤10åˆ†é’Ÿ, é˜Ÿåˆ—æ·±åº¦:128, ä»»åŠ¡æ•°:1)
4. éšæœºå†™é¢„çƒ­ (ä½¿ç”¨--ramp_timeå‚æ•°æŒ‡å®šæ—¶é—´, é»˜è®¤ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ, QD32/Job8)
5. 4Kéšæœºå†™å…¥æµ‹è¯• (ä½¿ç”¨-tå‚æ•°æŒ‡å®šæ—¶é—´, é»˜è®¤10åˆ†é’Ÿ, é˜Ÿåˆ—æ·±åº¦:32, ä»»åŠ¡æ•°:8)
6. 4Kéšæœºè¯»å–æµ‹è¯• (ä½¿ç”¨-tå‚æ•°æŒ‡å®šæ—¶é—´, é»˜è®¤10åˆ†é’Ÿ, é˜Ÿåˆ—æ·±åº¦:32, ä»»åŠ¡æ•°:8)

æ€»æ‰§è¡Œæ—¶é—´: é¢„çƒ­æ—¶é—´(é»˜è®¤20åˆ†é’Ÿ) + æµ‹è¯•æ—¶é—´ (é»˜è®¤40åˆ†é’Ÿ)

é¢„çƒ­ç­–ç•¥è¯´æ˜:
â€¢ é¡ºåºå†™é¢„çƒ­ä½¿ç”¨ä¸é¡ºåºå†™å®Œå…¨ç›¸åŒçš„å‚æ•°é…ç½® (QD128/Job1)
â€¢ éšæœºå†™é¢„çƒ­ä½¿ç”¨ä¸éšæœºå†™å®Œå…¨ç›¸åŒçš„å‚æ•°é…ç½® (QD32/Job8)
â€¢ --ramp_timeå‚æ•°é»˜è®¤è‡ªåŠ¨è®¾ç½®ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ,ä¹Ÿå¯æ‰‹åŠ¨æŒ‡å®š

æµ‹è¯•æ¨¡å‹è¯´æ˜:
â€¢ 128Ké¡ºåºè¯»/QD128/Job1 - å¤§æ–‡ä»¶é¡ºåºè¯»å†™æ€§èƒ½ (MB/s)
â€¢ 128Ké¡ºåºå†™/QD128/Job1 - å¤§æ–‡ä»¶é¡ºåºå†™å…¥æ€§èƒ½ (MB/s)
â€¢ 4Kéšæœºè¯»/QD32/Job8 - å°æ–‡ä»¶éšæœºè¯»å–æ€§èƒ½ (IOPS)
â€¢ 4Kéšæœºå†™/QD32/Job8 - å°æ–‡ä»¶éšæœºå†™å…¥æ€§èƒ½ (IOPS)

FIOå‘½ä»¤ç¤ºä¾‹(128Ké¡ºåºå†™å…¥):
fio --name=sequential_128k_write --filename=/dev/nvme0n1 --ioengine=libaio --direct=1 --numjobs=1 --iodepth=128 --rw=write --bs=128k --runtime=30 --ramp_time=15 --time_based=1 --size=100% --refill_buffers --end_fsync=1 --norandommap=1 --randrepeat=0 --group_reporting --output-format=json --output=sequential_128k_write.json

å˜å¼‚ç³»æ•°(CV)è¯´æ˜:
â€¢ CV < 0.1: æ•°æ®ç¨³å®šæ€§æå¥½(æ ‡å‡†å·®/å‡å€¼ < 10%)
â€¢ CV < 0.2: æ•°æ®ç¨³å®šæ€§è‰¯å¥½(æ ‡å‡†å·®/å‡å€¼ < 20%)  
â€¢ CV > 0.2: æ•°æ®æ³¢åŠ¨è¾ƒå¤§(æ ‡å‡†å·®/å‡å€¼ > 20%)

è¾“å‡ºæ–‡ä»¶:
â€¢ performance_report.csv  - CSVæ ¼å¼æ€§èƒ½æŠ¥å‘Š
â€¢ performance_report.json - JSONæ ¼å¼è¯¦ç»†æŠ¥å‘Š  
â€¢ system_info.txt        - ç³»ç»Ÿä¿¡æ¯å’Œæµ‹è¯•é…ç½®

æ›´æ–°å†…å®¹:
â€¢ å®ç°4ç§æ ‡å‡†SSDæ€§èƒ½æµ‹è¯•æ¨¡å‹
â€¢ ä¸ºæ¯ç§æµ‹è¯•æ¨¡å¼é…ç½®ä¸“ç”¨å‚æ•°
â€¢ å¢å¼ºæµ‹è¯•é…ç½®æ˜¾ç¤º
â€¢ æ·»åŠ æ•°æ®ç¨³å®šæ€§è¯„ä¼°(å˜å¼‚ç³»æ•°)
â€¢ æ–°å¢--ramp_timeå‚æ•°,é»˜è®¤è‡ªåŠ¨è®¾ç½®ä¸º-tå‚æ•°å€¼çš„ä¸€åŠ
â€¢ æ”¯æŒè‡ªå®šä¹‰é¢„çƒ­æ—¶é—´,ä¼˜åŒ–æµ‹è¯•æµç¨‹
"""
        print(help_text)
    
    def show_summary(self, results: List[TestResult]):
        """æ˜¾ç¤ºæµ‹è¯•æ€»ç»“"""
        self._display_detailed_summary(results)
        
    def _display_detailed_summary(self, results: List[TestResult]):
        """æ˜¾ç¤ºè¯¦ç»†æµ‹è¯•æ€»ç»“,åŒ…å«CVåˆ†æå’Œæ€§èƒ½è¯„ä¼°"""
        successful_tests = [r for r in results if r.evaluation.get("status") != "FAILED"]
        failed_tests = [r for r in results if r.evaluation.get("status") == "FAILED"]
        
        # è®¡ç®—æ•´ä½“ç»Ÿè®¡æ•°æ®
        overall_cv_analysis = self._calculate_overall_cv_analysis(successful_tests)
        performance_summary = self._generate_performance_summary(successful_tests)
        
        # æ˜¾ç¤ºæµ‹è¯•æ¦‚è§ˆ
        print(f"\n{Colors.BOLD}{Colors.CYAN}{'='*60}{Colors.END}")
        print(f"{Colors.BOLD}{Colors.CYAN}SSDæ€§èƒ½æµ‹è¯•å®Œæ•´è¯„ä¼°æŠ¥å‘Š{Colors.END}")
        print(f"{Colors.BOLD}{Colors.CYAN}{'='*60}{Colors.END}")
        
        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        print(f"\n{Colors.BOLD}ğŸ“Š æµ‹è¯•æ¦‚è§ˆ{Colors.END}")
        print(f"æ€»æµ‹è¯•æ•°: {len(results)}")
        print(f"æˆåŠŸæµ‹è¯•: {Colors.GREEN}{len(successful_tests)}{Colors.END}")
        print(f"å¤±è´¥æµ‹è¯•: {Colors.RED}{len(failed_tests)}{Colors.END}")
        print(f"æµ‹è¯•é€šè¿‡ç‡: {Colors.GREEN}{len(successful_tests)/len(results)*100:.1f}%{Colors.END}" if results else "0.0%")

        # CVç¨³å®šæ€§åˆ†æ
        self._display_cv_analysis(overall_cv_analysis)

        # æ€§èƒ½æ•°æ®è¯¦æƒ…
        self._display_performance_details(successful_tests)

        # æ€§èƒ½è¯„ä¼°ç»“è®º
        self._display_performance_conclusions(performance_summary, overall_cv_analysis)
        
        # å¤±è´¥æµ‹è¯•ä¿¡æ¯
        if failed_tests:
            self._display_failed_tests(failed_tests)
        
        print(f"\n{Colors.BOLD}{Colors.CYAN}{'='*60}{Colors.END}")
    
    def _calculate_overall_cv_analysis(self, successful_tests: List[TestResult]) -> Dict[str, Any]:
        """è®¡ç®—æ•´ä½“CVåˆ†ææ•°æ®"""
        if not successful_tests:
            return {"avg_cv": 0, "min_cv": 0, "max_cv": 0, "stability_rating": "æ— æ•°æ®"}
        
        cv_values = [r.statistics.get("cv", 0) for r in successful_tests]
        avg_cv = sum(cv_values) / len(cv_values)
        min_cv = min(cv_values)
        max_cv = max(cv_values)
        
        # ç¨³å®šæ€§è¯„çº§
        if avg_cv < 0.05:
            stability_rating = "å“è¶Š (CV<0.05)"
        elif avg_cv < 0.1:
            stability_rating = "æå¥½ (CV<0.1)"
        elif avg_cv < 0.2:
            stability_rating = "è‰¯å¥½ (CV<0.2)"
        else:
            stability_rating = "éœ€æ”¹è¿› (CV>0.2)"
            
        return {
            "avg_cv": avg_cv,
            "min_cv": min_cv,
            "max_cv": max_cv,
            "stability_rating": stability_rating,
            "cv_values": cv_values
        }
    
    def _generate_performance_summary(self, successful_tests: List[TestResult]) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æ‘˜è¦"""
        summary = {
            "sequential_write": None,
            "sequential_read": None,
            "random_write": None,
            "random_read": None
        }
        
        for result in successful_tests:
            test_key = f"{result.test_type}_{result.rw_pattern}"
            mean_value = result.statistics.get("mean", 0)
            
            if test_key == "sequential_write":
                summary["sequential_write"] = mean_value
            elif test_key == "sequential_read":
                summary["sequential_read"] = mean_value
            elif test_key == "random_write":
                summary["random_write"] = mean_value
            elif test_key == "random_read":
                summary["random_read"] = mean_value
                
        return summary
    
    def _display_cv_analysis(self, cv_analysis: Dict[str, Any]):
        """æ˜¾ç¤ºCVåˆ†æç»“æœ"""
        print(f"\n{Colors.BOLD}ğŸ“ˆ å˜å¼‚ç³»æ•°(CV)ç¨³å®šæ€§åˆ†æ{Colors.END}")
        print(f"å¹³å‡CVå€¼: {cv_analysis['avg_cv']:.3f} ({cv_analysis['avg_cv']*100:.1f}%)")
        print(f"CVèŒƒå›´: {cv_analysis['min_cv']:.3f} ~ {cv_analysis['max_cv']:.3f}")
        print(f"ç¨³å®šæ€§è¯„çº§: {Colors.GREEN}{cv_analysis['stability_rating']}{Colors.END}")
        
        # CVè§£é‡Šè¯´æ˜
        if cv_analysis['avg_cv'] < 0.1:
            print(f"ğŸ’¡ {Colors.GREEN}ç»“è®º: æ•°æ®ç¨³å®šæ€§æå¥½,æµ‹è¯•ç»“æœé«˜åº¦å¯é {Colors.END}")
        else:
            print(f"âš ï¸  {Colors.YELLOW}æ³¨æ„: æ•°æ®å­˜åœ¨ä¸€å®šæ³¢åŠ¨,å»ºè®®å¤šæ¬¡æµ‹è¯•éªŒè¯{Colors.END}")

    def _display_performance_details(self, successful_tests: List[TestResult]):
        """æ˜¾ç¤ºæ€§èƒ½æ•°æ®è¯¦æƒ…"""
        print(f"\n{Colors.BOLD}âš¡ è¯¦ç»†æ€§èƒ½æ•°æ®{Colors.END}")
        
        for result in successful_tests:
            test_name = f"{result.test_type} {result.block_size} {result.rw_pattern}"
            mean_value = result.statistics.get("mean", 0)
            cv = result.statistics.get("cv", 0)
            quality = result.evaluation.get("data_quality", "UNKNOWN")
            
            # æ ¹æ®æµ‹è¯•ç±»å‹ç¡®å®šæ ¼å¼å’Œå•ä½
            if "seq" in result.test_type:
                mean_str = f"{mean_value:.2f} MB/s"
                icon = "ğŸ“" if result.rw_pattern == "write" else "ğŸ“–"
            else:
                mean_str = f"{mean_value:,.0f} IOPS"
                icon = "âœï¸" if result.rw_pattern == "write" else "ğŸ”"
            
            # è´¨é‡è¯„çº§é¢œè‰²
            quality_color = Colors.GREEN if quality == "EXCELLENT" else Colors.YELLOW if quality == "GOOD" else Colors.RED
            
            print(f"  {icon} {test_name}:")
            print(f"     æ€§èƒ½: {Colors.BOLD}{mean_str}{Colors.END}")
            print(f"     CV: {cv:.3f} | è´¨é‡: {quality_color}{quality}{Colors.END}")

    def _display_performance_conclusions(self, performance_summary: Dict[str, Any], cv_analysis: Dict[str, Any]):
        """æ˜¾ç¤ºåŸºäºCVçš„æ€§èƒ½è¯„ä¼°ç»“è®º"""
        print(f"\n{Colors.BOLD}ğŸ¯ æ•°æ®ç¨³å®šæ€§è¯„ä¼°ç»“è®º{Colors.END}")
        
        # åŸºäºCVç¨³å®šæ€§çš„ç»¼åˆè¯„ä»·
        if cv_analysis['avg_cv'] < 0.01:
            stability_desc = "æ•°æ®æå…¶ç¨³å®š"
            reliability = "æé«˜"
            recommendation = "æµ‹è¯•ç»“æœé«˜åº¦å¯é ï¼Œå¯ç”¨äºé‡è¦æ€§èƒ½è¯„ä¼°"
        elif cv_analysis['avg_cv'] < 0.05:
            stability_desc = "æ•°æ®é«˜åº¦ç¨³å®š" 
            reliability = "å¾ˆé«˜"
            recommendation = "æµ‹è¯•ç»“æœå¯é ï¼Œå»ºè®®ä½œä¸ºåŸºå‡†æ€§èƒ½å‚è€ƒ"
        elif cv_analysis['avg_cv'] < 0.1:
            stability_desc = "æ•°æ®ç¨³å®šæ€§ä¼˜ç§€"
            reliability = "é«˜"
            recommendation = "æµ‹è¯•ç»“æœè¾ƒä¸ºå¯é ï¼Œé€‚åˆä¸€èˆ¬æ€§èƒ½è¯„ä¼°"
        else:
            stability_desc = "æ•°æ®å­˜åœ¨æ³¢åŠ¨"
            reliability = "ä¸­ç­‰"
            recommendation = "å»ºè®®å¢åŠ æµ‹è¯•æ¬¡æ•°ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœ"
        
        print(f"  ğŸ” ç¨³å®šæ€§: {stability_desc} (å¹³å‡CV: {cv_analysis['avg_cv']:.3f})")
        print(f"  ğŸ¯ å¯é æ€§: {reliability}")
        print(f"  ğŸ’¡ å»ºè®®: {recommendation}")
        
        # CVè´¨é‡åˆ†å¸ƒç»Ÿè®¡
        cv_values = cv_analysis.get('cv_values', [])
        if cv_values:
            excellent_count = sum(1 for cv in cv_values if cv < 0.05)
            good_count = sum(1 for cv in cv_values if 0.05 <= cv < 0.1)
            poor_count = sum(1 for cv in cv_values if cv >= 0.1)
            
            print(f"\n{Colors.BOLD}ğŸ“Š CVè´¨é‡åˆ†å¸ƒ{Colors.END}")
            print(f"  ä¼˜ç§€(CV<0.05): {excellent_count}/{len(cv_values)} é¡¹æµ‹è¯•")
            print(f"  è‰¯å¥½(0.05â‰¤CV<0.1): {good_count}/{len(cv_values)} é¡¹æµ‹è¯•")
            print(f"  æ³¢åŠ¨è¾ƒå¤§(CVâ‰¥0.1): {poor_count}/{len(cv_values)} é¡¹æµ‹è¯•")

    def _display_failed_tests(self, failed_tests: List[TestResult]):
        """æ˜¾ç¤ºå¤±è´¥æµ‹è¯•ä¿¡æ¯"""
        print(f"\n{Colors.BOLD}âŒ å¤±è´¥æµ‹è¯•è¯¦æƒ…{Colors.END}")
        for result in failed_tests:
            test_name = f"{result.test_type} {result.block_size} {result.rw_pattern}"
            error = result.evaluation.get("error", "Unknown error")
            print(f"  {Colors.RED}{test_name}: {error}{Colors.END}")
    
    def _update_time_parameters(self):
        """æ›´æ–°æ—¶é—´å‚æ•°"""
        self.stable_data_start_time = min(5, self.test_duration * 0.1)
        self.stable_data_end_time = min(self.test_duration - 5, self.test_duration * 0.9)
        self.sampling_interval = max(1, (self.stable_data_end_time - self.stable_data_start_time) / 4)
    
    def set_default_params(self, device: str):
        """æ ¹æ®è®¾å¤‡ç±»å‹è®¾ç½®é»˜è®¤å‚æ•°"""
        device_type = self.get_device_type(device)
        
        if device_type == "nvme":
            self.queue_depth = max(self.queue_depth, 64)
            self.threads = max(self.threads, 4)
        elif device_type == "sata_ssd":
            self.queue_depth = max(self.queue_depth, 32)
            self.threads = max(self.threads, 2)
        else:  # hdd or unknown
            self.queue_depth = min(self.queue_depth, 16)
            self.threads = min(self.threads, 2)
    
    def run(self) -> bool:
        """ä¸»æ‰§è¡Œå‡½æ•°"""
        if not self.parse_arguments():
            return False
            
        # è®¾å¤‡è®¿é—®æ£€æŸ¥
        if not self.check_device_access():
            return False
            
        # åˆ›å»ºç»“æœç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.result_dir = f"results_{self.device}_{timestamp}"
        os.makedirs(self.result_dir, exist_ok=True)
        
        self.log("INFO", f"ç»“æœç›®å½•: {self.result_dir}")

        # æ›´æ–°æ—¶é—´å‚æ•°
        self._update_time_parameters()

        # æ ¹æ®è®¾å¤‡ç±»å‹è®¾ç½®é»˜è®¤å‚æ•°
        self.set_default_params(self.device)

        # æ”¶é›†ç³»ç»Ÿä¿¡æ¯
        self.log("INFO", "æ”¶é›†ç³»ç»Ÿä¿¡æ¯...")
        system_info = self.collect_system_info()

        # æ˜¾ç¤ºæµ‹è¯•é…ç½®
        self.log("INFO", f"æµ‹è¯•è®¾å¤‡: {self.device} ({system_info.get('device_model', 'Unknown')}, {system_info.get('device_capacity_gb', 0):.1f} GB)")
        self.log("INFO", f"è®¾å¤‡ç±»å‹: {system_info.get('device_type', 'Unknown')}")
        self.log("INFO", f"æµ‹è¯•æ—¶é—´: {self.test_duration}ç§’, é¢„çƒ­æ—¶é—´: {self.ramp_time}ç§’")

        # è¿è¡Œæµ‹è¯•
        try:
            results = self.run_comprehensive_test()

            # ä¿å­˜ç»“æœ
            self.save_results(results, system_info)

            # æ˜¾ç¤ºæ€»ç»“
            self.show_summary(results)

            return True

        except KeyboardInterrupt:
            self.log("WARNING", "æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
            return False
        except Exception as e:
            self.log("ERROR", f"æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
            return False

def main():
    tester = SSDPerformanceTester()
    success = tester.run()
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()